{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "from pystoi import stoi\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pypesq import pesq\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 09:01:09.328017 140341936031232 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.contrib.keras.models.load_model('mixed_pos_snr_STFT_GRUx3_tanh_5epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取路徑\n",
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "\n",
    "    for root, directories, files in os.walk(directory):\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "                filepath = os.path.join(root, filename)\n",
    "                file_paths.append(filepath)  # Add it to the list.\n",
    "                # pdb.set_trace()\n",
    "\n",
    "    return file_paths  # Self-explanatory.\n",
    "mixed_file=get_filepaths('mixed_pos_snr/')\n",
    "cleaned_file=get_filepaths('clean/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64000,\n",
       " 64000,\n",
       " ['mixed_pos_snr/amanda_T23-1_20200626_ambulance_passing_snr12.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_breaking_concrete_snr4.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_breaking_houses2_snr11.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_breaking_houses4_snr9.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_car_road_snr13.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_construction2_snr13.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_fireengine_starting_snr9.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_house_construction_snr7.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_trains_passing1_snr9.wav',\n",
       "  'mixed_pos_snr/amanda_T23-1_20200626_trains_passing4_snr3.wav'],\n",
       " ['clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav',\n",
       "  'clean/amanda/amanda_T23-1_20200626.wav'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#整理檔案路徑排序\n",
    "#確認乾淨的答案有對應到混音完的檔案\n",
    "mixed_file = sorted(get_filepaths('mixed_pos_snr/'))\n",
    "clean_file = sorted(get_filepaths('clean/'))\n",
    "\n",
    "cleaned_file = []\n",
    "for data in clean_file:\n",
    "    for i in range(10):\n",
    "        cleaned_file += [data]\n",
    "        i += 1\n",
    "\n",
    "\n",
    "len(mixed_file), len(cleaned_file), mixed_file[5410:5420], cleaned_file[5410:5420]    # 確定排序  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出最長的音檔(88800),並變成相同長度\n",
    "max_len=0\n",
    "clean_filename=''\n",
    "for i in range(len(cleaned_file)):\n",
    "    path = cleaned_file[i]\n",
    "    noisy, rate  = librosa.load(path,sr=16000) \n",
    "    if noisy.shape[0]>max_len:\n",
    "        max_len=noisy.shape[0]\n",
    "        clean_filename = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85600, 'clean/saphira/saphira_T19-2_20200626.wav')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len,clean_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9782665530986326, 3.3639090061187744)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi_list = []\n",
    "pesq_list = []\n",
    "l=0\n",
    "for path in mixed_file[:16000]:\n",
    "    noisy, rate = librosa.load(path, sr=16000)\n",
    "    noisy = noisy.astype('float32')\n",
    "    noisy = np.hstack((noisy, np.zeros(85600 - noisy.shape[0])))\n",
    "    noisy_stft = librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "   \n",
    "    n_real = np.abs(noisy_stft)\n",
    "    n_real = n_real.T\n",
    "    n_phase = np.angle(noisy_stft)\n",
    "    n_real = n_real.reshape(1, n_real.shape[0], n_real.shape[1])\n",
    " \n",
    "    enhanced = model.predict(n_real)\n",
    "    enhanced = np.squeeze(enhanced).T\n",
    "    Rec = np.multiply(enhanced, np.exp(1j * n_phase))\n",
    "    \n",
    "    Rec = librosa.istft(Rec, hop_length=256, win_length=512, center=False)\n",
    "    Rec[100:-100] *= 50\n",
    "    Rec = (Rec - np.mean(Rec)) / np.std(Rec)\n",
    "    Rec = np.hstack((Rec, np.zeros(85600 - Rec.shape[0])))\n",
    "    \n",
    "    clean, sr = librosa.load(cleaned_file[l], sr=16000)\n",
    "    clean = np.hstack((clean, np.zeros(85600 - clean.shape[0])))\n",
    "   \n",
    "#     Clean and den should have the same length, and be 1D\n",
    "    pt_stoi = stoi(clean, Rec, 16000, extended=False)\n",
    "    stoi_list += [pt_stoi]\n",
    "    pt_pesq = pesq(clean, Rec, 16000)\n",
    "    pesq_list += [pt_pesq]\n",
    "    l += 1\n",
    "   \n",
    "max(stoi_list), max(pesq_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9277239362494457, 3.6452934741973877)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi_list01 = []\n",
    "pesq_list01 = []\n",
    "l=16000\n",
    "for path in mixed_file[16000:32000]:\n",
    "    noisy, rate = librosa.load(path, sr=16000)\n",
    "    noisy = noisy.astype('float32')\n",
    "    noisy = np.hstack((noisy, np.zeros(85600 - noisy.shape[0])))\n",
    "    noisy_stft = librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "   \n",
    "    n_real = np.abs(noisy_stft)\n",
    "    n_real = n_real.T\n",
    "    n_phase = np.angle(noisy_stft)\n",
    "    n_real = n_real.reshape(1, n_real.shape[0], n_real.shape[1])\n",
    " \n",
    "    enhanced = model.predict(n_real)\n",
    "    enhanced = np.squeeze(enhanced).T\n",
    "    Rec = np.multiply(enhanced, np.exp(1j * n_phase))\n",
    "    \n",
    "    Rec = librosa.istft(Rec, hop_length=256, win_length=512, center=False)\n",
    "    Rec[100:-100] *= 50\n",
    "    Rec = (Rec - np.mean(Rec)) / np.std(Rec)\n",
    "    Rec = np.hstack((Rec, np.zeros(85600 - Rec.shape[0])))\n",
    "    \n",
    "    clean, sr = librosa.load(cleaned_file[l], sr=16000)\n",
    "    clean = np.hstack((clean, np.zeros(85600 - clean.shape[0])))\n",
    "   \n",
    "#     Clean and den should have the same length, and be 1D\n",
    "    pt_stoi = stoi(clean, Rec, 16000, extended=False)\n",
    "    stoi_list01 += [pt_stoi]\n",
    "    pt_pesq = pesq(clean, Rec, 16000)\n",
    "    pesq_list01 += [pt_pesq]\n",
    "    l += 1\n",
    "   \n",
    "max(stoi_list01), max(pesq_list01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9441466670695038, 3.4864654541015625)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi_list02 = []\n",
    "pesq_list02 = []\n",
    "l=32000\n",
    "for path in mixed_file[32000:48000]:\n",
    "    noisy, rate = librosa.load(path, sr=16000)\n",
    "    noisy = noisy.astype('float32')\n",
    "    noisy = np.hstack((noisy, np.zeros(85600 - noisy.shape[0])))\n",
    "    noisy_stft = librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "   \n",
    "    n_real = np.abs(noisy_stft)\n",
    "    n_real = n_real.T\n",
    "    n_phase = np.angle(noisy_stft)\n",
    "    n_real = n_real.reshape(1, n_real.shape[0], n_real.shape[1])\n",
    " \n",
    "    enhanced = model.predict(n_real)\n",
    "    enhanced = np.squeeze(enhanced).T\n",
    "    Rec = np.multiply(enhanced, np.exp(1j * n_phase))\n",
    "    \n",
    "    Rec = librosa.istft(Rec, hop_length=256, win_length=512, center=False)\n",
    "    Rec[100:-100] *= 50\n",
    "    Rec = (Rec - np.mean(Rec)) / np.std(Rec)\n",
    "    Rec = np.hstack((Rec, np.zeros(85600 - Rec.shape[0])))\n",
    "    \n",
    "    clean, sr = librosa.load(cleaned_file[l], sr=16000)\n",
    "    clean = np.hstack((clean, np.zeros(85600 - clean.shape[0])))\n",
    "   \n",
    "#     Clean and den should have the same length, and be 1D\n",
    "    pt_stoi = stoi(clean, Rec, 16000, extended=False)\n",
    "    stoi_list02 += [pt_stoi]\n",
    "    pt_pesq = pesq(clean, Rec, 16000)\n",
    "    pesq_list02 += [pt_pesq]\n",
    "    l += 1\n",
    "   \n",
    "max(stoi_list02), max(pesq_list02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9724147990125118, 3.364743709564209)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi_list03 = []\n",
    "pesq_list03 = []\n",
    "l=48000\n",
    "for path in mixed_file[48000:64000]:\n",
    "    noisy, rate = librosa.load(path, sr=16000)\n",
    "    noisy = noisy.astype('float32')\n",
    "    noisy = np.hstack((noisy, np.zeros(85600 - noisy.shape[0])))\n",
    "    noisy_stft = librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "   \n",
    "    n_real = np.abs(noisy_stft)\n",
    "    n_real = n_real.T\n",
    "    n_phase = np.angle(noisy_stft)\n",
    "    n_real = n_real.reshape(1, n_real.shape[0], n_real.shape[1])\n",
    " \n",
    "    enhanced = model.predict(n_real)\n",
    "    enhanced = np.squeeze(enhanced).T\n",
    "    Rec = np.multiply(enhanced, np.exp(1j * n_phase))\n",
    "    \n",
    "    Rec = librosa.istft(Rec, hop_length=256, win_length=512, center=False)\n",
    "    Rec[100:-100] *= 50\n",
    "    Rec = (Rec - np.mean(Rec)) / np.std(Rec)\n",
    "    Rec = np.hstack((Rec, np.zeros(85600 - Rec.shape[0])))\n",
    "    \n",
    "    clean, sr = librosa.load(cleaned_file[l], sr=16000)\n",
    "    clean = np.hstack((clean, np.zeros(85600 - clean.shape[0])))\n",
    "   \n",
    "#     Clean and den should have the same length, and be 1D\n",
    "    pt_stoi = stoi(clean, Rec, 16000, extended=False)\n",
    "    stoi_list03 += [pt_stoi] \n",
    "    pt_pesq = pesq(clean, Rec, 16000)\n",
    "    pesq_list03 += [pt_pesq] \n",
    "    l += 1\n",
    "   \n",
    "max(stoi_list03), max(pesq_list03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_stoi = (stoi_list + stoi_list01 + stoi_list02 + stoi_list03)\n",
    "tot_pesq = (pesq_list + pesq_list01 + pesq_list02 + pesq_list03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sor_tot_stoi = sorted(tot_stoi)\n",
    "sor_tot_pesq = sorted(tot_pesq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46750"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(tot_pesq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mixed_pos_snr/ryan_T20-5_20200620_ambulance_passing_snr14.wav'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_file[46750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9782665530986326,\n",
       "  0.9775086680408039,\n",
       "  0.9774873002722295,\n",
       "  0.976089331391819,\n",
       "  0.9758601787479622],\n",
       " ['mixed_pos_snr/blue_T27-10_20200710_fireengine_starting_snr14.wav',\n",
       "  'mixed_pos_snr/blue_T27-10_20200710_ambulance_passing_snr2.wav',\n",
       "  'mixed_pos_snr/blue_T04-2_20200710_fireengine_starting_snr15.wav',\n",
       "  'mixed_pos_snr/blue_T26-10_20200710_ambulance_passing_snr15.wav',\n",
       "  'mixed_pos_snr/blue_T10-2_20200710_fireengine_starting_snr14.wav'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lst=[]\n",
    "name_lst=[]\n",
    "for i in range(1,6):\n",
    "    max1 = tot_stoi.index(sor_tot_stoi[-i])\n",
    "    name_lst.append(mixed_file[max1])\n",
    "    score_lst.append(tot_stoi[max1])\n",
    "score_lst,name_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.6452934741973877,\n",
       "  3.608628273010254,\n",
       "  3.5849177837371826,\n",
       "  3.5654938220977783,\n",
       "  3.554208755493164],\n",
       " ['mixed_pos_snr/ryan_T20-5_20200620_ambulance_passing_snr14.wav',\n",
       "  'mixed_pos_snr/ryan_T04-6_20200620_ambulance_passing_snr12.wav',\n",
       "  'mixed_pos_snr/ryan_T28-6_20200620_ambulance_passing_snr6.wav',\n",
       "  'mixed_pos_snr/ryan_T19-10_20200620_ambulance_passing_snr14.wav',\n",
       "  'mixed_pos_snr/ryan_T04-8_20200620_ambulance_passing_snr2.wav'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lst1=[]\n",
    "name_lst1=[]\n",
    "for i in range(1,6):\n",
    "    max2 = tot_pesq.index(sor_tot_pesq[-i])\n",
    "    name_lst1.append(mixed_file[max2])\n",
    "    score_lst1.append(tot_pesq[max2])\n",
    "score_lst1,name_lst1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782665530986326"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_stoi[max1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first stoi : 0.9782665530986326\n",
      "second stoi : 0.9775086680408039\n",
      "third stoi : 0.9774873002722295\n"
     ]
    }
   ],
   "source": [
    "print(f'first stoi : {sor_tot_stoi[-1]}'),\n",
    "print(f'second stoi : {sor_tot_stoi[-2]}'),\n",
    "print(f'third stoi : {sor_tot_stoi[-3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first pesq : 3.6452934741973877\n",
      "second pesq : 3.608628273010254\n",
      "third pesq : 3.5849177837371826\n"
     ]
    }
   ],
   "source": [
    "print(f'first pesq : {sor_tot_pesq[-1]}'),\n",
    "print(f'second pesq : {sor_tot_pesq[-2]}'),\n",
    "print(f'third pesq : {sor_tot_pesq[-3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PESQ : 3.6452934741973877 , name : ryan_T20-5_20200620_ambulance_passing_snr14.wav\n",
      "PESQ : 3.6086282730102546 , name : ryan_T04-6_20200620_ambulance_passing_snr12.wav\n",
      "PESQ : 3.5849177837371826 , name : ryan_T28-6_20200620_ambulance_passing_snr6.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'PESQ : 3.6452934741973877 , name : ryan_T20-5_20200620_ambulance_passing_snr14.wav'),\n",
    "print(f'PESQ : 3.6086282730102546 , name : ryan_T04-6_20200620_ambulance_passing_snr12.wav'),\n",
    "print(f'PESQ : 3.5849177837371826 , name : ryan_T28-6_20200620_ambulance_passing_snr6.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOI : 0.9782665530986326 , name : blue_T27-10_20200710_fireengine_starting_snr14.wav\n",
      "STOI : 0.9775086680408039 , name : blue_T27-10_20200710_ambulance_passing_snr2.wav\n",
      "STOI : 0.9774873002722295 , name : blue_T04-2_20200710_fireengine_starting_snr15.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'STOI : 0.9782665530986326 , name : blue_T27-10_20200710_fireengine_starting_snr14.wav'),\n",
    "print(f'STOI : 0.9775086680408039 , name : blue_T27-10_20200710_ambulance_passing_snr2.wav'),\n",
    "print(f'STOI : 0.9774873002722295 , name : blue_T04-2_20200710_fireengine_starting_snr15.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PESQ : 3.8121867179870605 , name : saphira_T13-9_20200626_ambulance_passing_snr13.wav\n",
      "PESQ : 3.8036730289459232 , name : blue_T03-8_20200710_ambulance_passing_snr5.wav\n",
      "PESQ : 3.7971813678741455 , name : jin_T18-2_20200620_ambulance_passing_snr12.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'PESQ : 3.8121867179870605 , name : saphira_T13-9_20200626_ambulance_passing_snr13.wav'),\n",
    "print(f'PESQ : 3.8036730289459232 , name : blue_T03-8_20200710_ambulance_passing_snr5.wav'),\n",
    "print(f'PESQ : 3.7971813678741455 , name : jin_T18-2_20200620_ambulance_passing_snr12.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOI : 0.9909236116918912 , name : blue_T19-3_20200710_ambulance_passing_snr14.wav\n",
      "STOI : 0.9901033438609617 , name : blue_T27-10_20200710_ambulance_passing_snr8.wav\n",
      "STOI : 0.9900976538725138 , name : blue_T20-2_20200710_ambulance_passing_snr14.wav\n"
     ]
    }
   ],
   "source": [
    "print(f'STOI : 0.9909236116918912 , name : blue_T19-3_20200710_ambulance_passing_snr14.wav'),\n",
    "print(f'STOI : 0.9901033438609617 , name : blue_T27-10_20200710_ambulance_passing_snr8.wav'),\n",
    "print(f'STOI : 0.9900976538725138 , name : blue_T20-2_20200710_ambulance_passing_snr14.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stoi 評分\n",
    "\n",
    "clean, fs = sf.read('path/to/clean/audio')\n",
    "denoised, fs = sf.read('path/to/denoised/audio')\n",
    "\n",
    "# Clean and den should have the same length, and be 1D\n",
    "d = stoi(clean, denoised, fs, extended=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystoi import stoi\n",
    "from pypesq import pesq\n",
    "\n",
    "\n",
    "i = 0\n",
    "stoi_list = []\n",
    "pesq_list = []\n",
    "for path in mixed_file:\n",
    "    noisy, rate = librosa.load(path, sr=16000)\n",
    "    noisy = noisy.astype('float32')\n",
    "    noisy = np.hstack((noisy, np.zeros(85600 - noisy.shape[0])))\n",
    "    noisy_stft = librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "\n",
    "    n_real = np.abs(noisy_stft)\n",
    "    n_phase = np.angle(noisy_stft)\n",
    "    n_real = n_real.reshape(1, n_real.shape[0], n_real.shape[1], 1)\n",
    "\n",
    "    model._make_predict_function()\n",
    "\n",
    "    enhanced = model.predict(n_real)\n",
    "    enhanced = np.squeeze(enhanced)\n",
    "    Rec = np.multiply(enhanced, np.exp(1j * n_phase))\n",
    "\n",
    "    Rec = librosa.istft(Rec, hop_length=256, win_length=512, center=False)\n",
    "    Rec[100:-100] *= 50\n",
    "    Rec = (Rec - np.mean(Rec)) / np.std(Rec)\n",
    "    \n",
    "    clean, sr = librosa.load(cleaned_file[i], sr=16000)\n",
    "    clean = np.hstack((clean, np.zeros(85504 - clean.shape[0])))\n",
    "    \n",
    "    # Clean and den should have the same length, and be 1D\n",
    "    pt_stoi = stoi(clean, Rec, 16000, extended=False)\n",
    "    stoi_list += [pt_stoi]\n",
    "    pt_pesq = pesq(clean, Rec, 16000)\n",
    "    pesq_list += [pt_pesq]\n",
    "    i += 1\n",
    "\n",
    "max(stoi_list), max(pesq_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
