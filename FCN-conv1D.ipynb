{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "# matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation, SpatialDropout2D, Reshape, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU, PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from scipy.io import wavfile\n",
    "import pdb\n",
    "import scipy.io\n",
    "import librosa\n",
    "import os\n",
    "from os.path import join as ojoin\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import time  \n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import argparse\n",
    "import random\n",
    "import theano\n",
    "# os.environ['KERAS_BACKEND'] = 'theano'\n",
    "# import theano.tensor as T\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "# from keras.utils import to_categorical,plot_model\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "\n",
    "    for root, directories, files in os.walk(directory):\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "                filepath = os.path.join(root, filename)\n",
    "                file_paths.append(filepath)  # Add it to the list.\n",
    "                # pdb.set_trace()\n",
    "\n",
    "    return file_paths  # Self-explanatory.\n",
    "mixed_file=get_filepaths('mixed_pos_snr')\n",
    "cleaned_file=get_filepaths('clean')\n",
    "pos=get_filepaths('mixed_pos_snr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整理檔案路徑排序\n",
    "#確認乾淨的答案有對應到混音完的檔案\n",
    "clean_files=[]\n",
    "for i in mixed_file:\n",
    "    clean_file='_'.join(i.split('\\\\')[1].split('_')[:3])+'.wav'\n",
    "    for j in cleaned_file:\n",
    "#         print(j)\n",
    "        if clean_file == j.split('\\\\')[-1]:\n",
    "            clean_files.append(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav',\n",
       " 'clean\\\\amanda\\\\amanda_T01-10_20200626.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##切分train-test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(mixed_file,clean_files,test_size=0.33, random_state=42)    \n",
    "Train_Noisy_lists=X_train\n",
    "Train_Clean_paths= y_train\n",
    "\n",
    "Test_Noisy_lists  = X_test\n",
    "Test_Clean_paths = y_test\n",
    "          \n",
    "Num_testdata=len(Test_Noisy_lists)   \n",
    "Num_traindata=len(Train_Noisy_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator(noisy_list, clean_path):\n",
    "    index=0\n",
    "    while True:\n",
    "        noisy, rate  = librosa.load(noisy_list[index],sr=16000) \n",
    "        # print(noisy_list[index],index)\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        D=librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "        noisy = np.abs(D)\n",
    "        #轉向因為高固定 但長度不同\n",
    "        noisy = noisy.T\n",
    "        noisy=np.reshape(noisy,(1,np.shape(noisy)[0],np.shape(noisy)[1]))\n",
    "        noisy_shi=np.angle(D)\n",
    "\n",
    "\n",
    "        clean, rate  =librosa.load(clean_path[index],sr=16000) \n",
    "        D=librosa.stft(clean,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "        clean = np.abs(D)\n",
    "        #轉向因為高固定 但長度不同\n",
    "        clean = clean.T\n",
    "        clean=np.reshape(clean,(1,np.shape(clean)[0],np.shape(clean)[1]))\n",
    "        clean_shi=np.angle(D)\n",
    "\n",
    "        index += 1\n",
    "        if index == len(noisy_list):\n",
    "            index = 0\n",
    "\n",
    "        yield noisy, clean\n",
    "\n",
    "def val_data_generator(noisy_list, clean_path):\n",
    "    index=0\n",
    "    while True:\n",
    "        noisy, rate  = librosa.load(noisy_list[index],sr=16000)       \n",
    "        D=librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "        noisy = np.abs(D)\n",
    "        #轉向因為高固定 但長度不同\n",
    "        noisy = noisy.T\n",
    "        noisy=np.reshape(noisy,(1,np.shape(noisy)[0],np.shape(noisy)[1]))\n",
    "        noisy_shi=np.angle(D)\n",
    "          \n",
    "        clean, rate  =librosa.load(clean_path[index],sr=16000) \n",
    "        D=librosa.stft(clean,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "        clean = np.abs(D)\n",
    "        #轉向因為高固定 但長度不同\n",
    "        clean = clean.T\n",
    "        clean=np.reshape(clean,(1,np.shape(clean)[0],np.shape(clean)[1]))\n",
    "        clean_shi=np.angle(D)\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if index == len(noisy_list):\n",
    "            index = 0\n",
    "          \n",
    "        yield noisy, clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model building...\n",
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 60)          848160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 60)          240       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, None, 60)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 60)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 80)          264080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 80)          320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 80)          352080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 80)          320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 100)         440100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 100)         550100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 120)         660120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, None, 120)         480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, None, 120)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, None, 120)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 257)         1696457   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, None, 257)         0         \n",
      "=================================================================\n",
      "Total params: 4,813,257\n",
      "Trainable params: 4,812,177\n",
      "Non-trainable params: 1,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('model building...')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv1D(60, 55, padding='same', input_shape=(None,257)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(80, 55,  padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(80, 55,  padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(100, 55,  padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(100, 55,  padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(120, 55,  padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(257, 55,  padding='same'))\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "\n",
    "# model.load_weights('firsttry')\n",
    "model.summary()\n",
    "\n",
    "#sgd = SGD(lr=0.001, decay=5*1e-8, momentum=0.9, nesterov=True)\n",
    "# plot_model(model,show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., verbose=1, validation_data=<generator..., steps_per_epoch=45024, epochs=5, validation_steps=22176, workers=1, use_multiprocessing=False, max_queue_size=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/5\n",
      "45024/45024 [==============================] - 1420s 32ms/step - loss: 0.0302 - val_loss: 0.0274\n",
      "Epoch 2/5\n",
      "45024/45024 [==============================] - 1622s 36ms/step - loss: 0.0224 - val_loss: 0.0295\n",
      "Epoch 3/5\n",
      "45024/45024 [==============================] - 1366s 30ms/step - loss: 0.0198 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "45024/45024 [==============================] - 1369s 30ms/step - loss: 0.0182 - val_loss: 0.0276\n",
      "Epoch 5/5\n",
      "45024/45024 [==============================] - 1372s 30ms/step - loss: 0.0170 - val_loss: 0.0254\n"
     ]
    }
   ],
   "source": [
    "epoch=5\n",
    "batch_size=1\n",
    "# Adam=tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "with open('{}.json'.format('firsttry'),'w') as f:    # save the model\n",
    "    f.write(model.to_json()) \n",
    "checkpointer = ModelCheckpoint(filepath='{}.hdf5'.format('firsttry'), verbose=1, save_best_only=True, mode='min')  \n",
    "\n",
    "print ('training...')\n",
    "\n",
    "g1 = train_data_generator(Train_Noisy_lists, Train_Clean_paths)\n",
    "g2 = val_data_generator(Test_Noisy_lists, Test_Clean_paths)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "#                  batch_size=32,     # 用多大量的数据计算直方图\n",
    "                 write_graph=True,  # 是否存储网络结构图\n",
    "                 write_grads=True, # 是否可视化梯度直方图\n",
    "                 write_images=True,# 是否可视化参数\n",
    "                 embeddings_freq=0, \n",
    "                 embeddings_layer_names=None, \n",
    "                 embeddings_metadata=None)\n",
    "hist=model.fit_generator(g1,\n",
    "                         samples_per_epoch=Num_traindata,\n",
    "                        # samples_per_epoch=50, \n",
    "                         nb_epoch=epoch, \n",
    "                         verbose=1,\n",
    "                         validation_data=g2,\n",
    "                         nb_val_samples=Num_testdata,\n",
    "                         max_q_size=1, \n",
    "                         nb_worker=1,\n",
    "                         pickle_safe=False,\n",
    "                         )                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存h5檔\n",
    "sav=model.save('mixed_all_snr_raw_1dx9_15epoch.h5')\n",
    "sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@0.025445, Minimun error:0.025445, at iteration: 5\n",
      "The code for this file ran for 120.30m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "## 畫Loss圖\n",
    "\n",
    "# # plotting the learning curve\n",
    "TrainERR=hist.history['loss']\n",
    "ValidERR=hist.history['val_loss']\n",
    "print ('@%f, Minimun error:%f, at iteration: %i' % (hist.history['val_loss'][epoch-1], np.min(np.asarray(ValidERR)),np.argmin(np.asarray(ValidERR))+1))\n",
    "# print 'drawing the training process...'\n",
    "plt.clf()\n",
    "plt.figure(4)\n",
    "plt.plot(range(1,epoch+1),TrainERR,'b',label='TrainERR')\n",
    "plt.plot(range(1,epoch+1),ValidERR,'r',label='ValidERR')\n",
    "plt.xlim([1,epoch])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('Learning_curve_{sav}.png', dpi=150)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The code for this file ran for %.2fm' % ((end_time - start_time) / 60.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 257)\n",
      "(188, 257)\n",
      "(164, 257)\n",
      "(213, 257)\n",
      "(170, 257)\n",
      "(175, 257)\n",
      "(233, 257)\n",
      "(208, 257)\n",
      "(195, 257)\n",
      "(177, 257)\n"
     ]
    }
   ],
   "source": [
    "maxv = np.iinfo(np.int16).max \n",
    "for path in Test_Noisy_lists[:10]: # Ex: /mnt/hd-02/avse/testing/noisy/engine/1dB/1.wav\n",
    "    S=path.split('\\\\') \n",
    "    # noise=S[-3]\n",
    "    # dB=S[-2]\n",
    "    wave_name=S[1]\n",
    "    noisy, rate  = librosa.load(path,sr=16000) \n",
    "    noisy=noisy.astype('float32')\n",
    "    # print(noisy_list[index],index)\n",
    "    # pdb.set_trace()\n",
    "    D=librosa.stft(noisy,n_fft=512,hop_length=256,win_length=512,center=False)\n",
    "    noisy = np.abs(D)\n",
    "    #轉向因為高固定 但長度不同\n",
    "    noisy = noisy.T\n",
    "    print(noisy.shape)\n",
    "    noisy_shi=np.angle(D)\n",
    "\n",
    "    noisy=np.reshape(noisy,(1,np.shape(noisy)[0],np.shape(noisy)[1]))\n",
    "#     print('reshape====>',noisy.shape)\n",
    "    enhanced=np.squeeze( model.predict(noisy, batch_size=1)).T\n",
    "#     print(enhanced.shape)\n",
    "    Rec = np.multiply(enhanced, np.exp(1j * noisy_shi))\n",
    "    enhanced=librosa.istft(Rec,hop_length=256,win_length=512,center=False)\n",
    "#     enhanced=enhanced/np.max(abs(enhanced))\n",
    "    enhanced=enhanced* maxv\n",
    "    enhanced_2=enhanced.astype('int16')\n",
    "#     enhanced=enhanced/2**15\n",
    "    wavfile.write(os.path.join(\"c:\\\\test\", wave_name),16000,(enhanced).astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.contrib.keras.models.load_model('mixed_pos_snr_raw_1dx7_10epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22a89e2cdc8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyhht.visualization import plot_imfs\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "path = 'D:\\\\result\\\\mixed_all_snr_STFT_1dx9_15epoch\\\\jiawei_T21-5_20200626_trains_passing1_snr2.wav' \n",
    "data , sr = librosa.load(path,sr=16000) \n",
    "# data = data/abs(data).max()\n",
    "plt.plot(data)\n",
    "# ipd.Audio(data,rate=16000) #播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
